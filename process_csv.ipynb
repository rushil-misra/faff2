{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2dc9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('messages_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba5a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b868b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"chats\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8ac06",
   "metadata": {},
   "source": [
    "dataset needs to reversed, rn it is latest - first\n",
    "we need increasing order to build context as we go down the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1\n",
    "for chat_id, group_df in file.groupby(\"chat_id\"):\n",
    "    filename = f\"chat_{id}.csv\"\n",
    "    filepath = os.path.join(output, filename)\n",
    "    group_df = group_df.iloc[::-1]\n",
    "    group_df.to_csv(filepath, index=False)\n",
    "    id += 1\n",
    "    print(f\"Saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1 = pd.read_csv('chats/chat_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1['from_number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_2 = pd.read_csv('chats/chat_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3540b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_2['from_number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f27615",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1['text_body'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(chat_1['from_number'][i],\"--\",chat_1['text_body'][i],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb29b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1_new = chat_1[['message_id','type','text_body','from_number','media_url','context','created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cf53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1_new['created_at'] = pd.to_datetime(chat_1_new['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfbce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5852828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if user is talking about themselves\n",
    "# determine if it is anything important\n",
    "# future scope - integrate context\n",
    "# future scope - check with before messages\n",
    "def user_facts(text):\n",
    "    if bool(re.search(r\"\\b(I|my|me|we)\\b\", text, re.IGNORECASE)):\n",
    "        extracted_fact = llm.invoke(f'your task is to determine if the following message gives any information about the user {text}. If it does, write it in simple manner. If it does not, simply write no').content\n",
    "        if re.fullmatch(r\"\\b(no)\\b\", extracted_fact, re.IGNORECASE):\n",
    "            print(\"Not useful\")\n",
    "            return None\n",
    "        else:\n",
    "            print(extracted_fact)\n",
    "            return extracted_fact\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce57e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_user = ['message_id','from_number','text_body','facts','created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a35bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_facts_csv = pd.DataFrame(columns=columns_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f541e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_facts(chat_1_new['text_body'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_1_new['text_body'] = chat_1_new['text_body'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d4ae5",
   "metadata": {},
   "source": [
    "i need id of every message with info to cross check so i need to iterate every message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(chat_1_new)):\n",
    "    response = user_facts(chat_1_new['text_body'][i])\n",
    "    if response != 'Not useful' or response != 'No':\n",
    "        user_fact_row = {\n",
    "            'message_id' : chat_1_new['message_id'][i],\n",
    "            'from_number' : chat_1_new['from_number'][i],\n",
    "            'text_body' : chat_1_new['text_body'][i],\n",
    "            'facts' : response,\n",
    "            'created_at' : chat_1_new['created_at'][i]\n",
    "\t\t\t\t\t\t\t\t}\n",
    "        user_facts_csv = pd.concat([user_facts_csv,pd.DataFrame([user_fact_row])],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4972cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_facts_csv['facts'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2513fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_facts_csv = user_facts_csv[user_facts_csv['facts'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_facts_csv.to_csv(\"users_new.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_facts_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import uuid\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb89ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_task_request(text):\n",
    "    \"\"\"\n",
    "    Determine if the message contains a task request\n",
    "    \"\"\"\n",
    "    # Look for task-indicating patterns\n",
    "    task_patterns = [\n",
    "        r\"\\b(can you|could you|please|help me|I need|do this|make this|create|build|fix|solve)\\b\",\n",
    "        r\"\\b(task|todo|assignment|project|work|job)\\b\",\n",
    "        r\"\\?\",  # Questions often indicate requests\n",
    "        r\"\\b(urgent|asap|deadline|by tomorrow|need it)\\b\"\n",
    "    ]\n",
    "    \n",
    "    has_task_indicators = any(re.search(pattern, text, re.IGNORECASE) for pattern in task_patterns)\n",
    "    \n",
    "    if has_task_indicators:\n",
    "        # Use LLM to determine if it's actually a task request\n",
    "        extracted_task = llm.invoke(\n",
    "            f'''Analyze this message to determine if the user is requesting a task to be performed: \"{text}\"\n",
    "            \n",
    "            If this is a task request, respond with:\n",
    "            1. A brief title for the task (max 50 chars)\n",
    "            2. A description of what needs to be done\n",
    "            3. Any deadline or urgency mentioned\n",
    "            \n",
    "            Format your response as:\n",
    "            TITLE: [task title]\n",
    "            DESCRIPTION: [what needs to be done]\n",
    "            DEADLINE: [any deadline mentioned or \"None\"]\n",
    "            \n",
    "            If this is NOT a task request, simply respond with \"NO_TASK\"'''\n",
    "        ).content\n",
    "        \n",
    "        if \"NO_TASK\" in extracted_task.upper():\n",
    "            return None\n",
    "        else:\n",
    "            return extracted_task\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbae5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_task_update(text, existing_tasks):\n",
    "    \"\"\"\n",
    "    Check if the message contains updates about existing tasks\n",
    "    \"\"\"\n",
    "    if not existing_tasks:\n",
    "        return None\n",
    "    \n",
    "    # Create a summary of existing tasks for context\n",
    "    task_context = \"\\n\".join([f\"Task {i+1}: {task['title']}\" for i, task in enumerate(existing_tasks)])\n",
    "    \n",
    "    update_response = llm.invoke(\n",
    "        f'''Given these existing tasks:\n",
    "        {task_context}\n",
    "        \n",
    "        Analyze this message: \"{text}\"\n",
    "        \n",
    "        Does this message provide an update, progress report, completion status, or modification request for any of the existing tasks?\n",
    "        \n",
    "        If YES, respond with:\n",
    "        TASK_NUMBER: [which task number this relates to]\n",
    "        UPDATE_TYPE: [progress/completion/modification/question]\n",
    "        UPDATE: [brief description of the update]\n",
    "        \n",
    "        If NO, respond with \"NO_UPDATE\"'''\n",
    "    ).content\n",
    "    \n",
    "    if \"NO_UPDATE\" in update_response.upper():\n",
    "        return None\n",
    "    else:\n",
    "        return update_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8612db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dataframes\n",
    "task_requests_df = pd.DataFrame(columns=[\n",
    "    'task_id', 'message_id', 'from_number', 'text_body', 'task_title', \n",
    "    'task_description', 'deadline', 'status', 'created_at'\n",
    "])\n",
    "\n",
    "task_updates_df = pd.DataFrame(columns=[\n",
    "    'update_id', 'task_id', 'message_id', 'from_number', 'text_body', \n",
    "    'update_type', 'update_description', 'created_at'\n",
    "])\n",
    "\n",
    "# Track tasks as we process messages\n",
    "active_tasks = []\n",
    "\n",
    "# Process messages chronologically\n",
    "# chat_1_sorted = chat_1_new.sort_values('created_at').reset_index(drop=True)\n",
    "\n",
    "for i in range(len(chat_1_new)):\n",
    "    message_text = chat_1_new['text_body'][i]\n",
    "    from_number = chat_1_new['from_number'][i]\n",
    "    message_id = chat_1_new['message_id'][i]\n",
    "    created_at = chat_1_new['created_at'][i]\n",
    "    \n",
    "    # Skip empty messages\n",
    "    if pd.isna(message_text) or message_text.strip() == '':\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing message {i+1}/{len(chat_1_new)}: {message_text[:50]}...\")\n",
    "    \n",
    "    # Check for new task requests\n",
    "    task_response = extract_task_request(message_text)\n",
    "    \n",
    "    if task_response:\n",
    "        # Generate unique task ID\n",
    "        task_id = str(uuid.uuid4())[:8]\n",
    "        \n",
    "        # Parse the LLM response\n",
    "        lines = task_response.split('\\n')\n",
    "        task_title = \"Untitled Task\"\n",
    "        task_description = message_text[:100] + \"...\"\n",
    "        deadline = \"None\"\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.startswith('TITLE:'):\n",
    "                task_title = line.replace('TITLE:', '').strip()\n",
    "            elif line.startswith('DESCRIPTION:'):\n",
    "                task_description = line.replace('DESCRIPTION:', '').strip()\n",
    "            elif line.startswith('DEADLINE:'):\n",
    "                deadline = line.replace('DEADLINE:', '').strip()\n",
    "        \n",
    "        # Add to task requests dataframe\n",
    "        task_row = {\n",
    "            'task_id': task_id,\n",
    "            'message_id': message_id,\n",
    "            'from_number': from_number,\n",
    "            'text_body': message_text,\n",
    "            'task_title': task_title,\n",
    "            'task_description': task_description,\n",
    "            'deadline': deadline,\n",
    "            'status': 'requested',\n",
    "            'created_at': created_at\n",
    "        }\n",
    "        \n",
    "        task_requests_df = pd.concat([task_requests_df, pd.DataFrame([task_row])], ignore_index=True)\n",
    "        \n",
    "        # Add to active tasks for tracking\n",
    "        active_tasks.append({\n",
    "            'task_id': task_id,\n",
    "            'title': task_title,\n",
    "            'requester': from_number\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ… New task identified: {task_title}\")\n",
    "    \n",
    "    # Check for updates on existing tasks\n",
    "    if active_tasks:\n",
    "        update_response = extract_task_update(message_text, active_tasks)\n",
    "        \n",
    "        if update_response:\n",
    "            # Parse the update response\n",
    "            lines = update_response.split('\\n')\n",
    "            task_number = None\n",
    "            update_type = \"progress\"\n",
    "            update_description = message_text[:100] + \"...\"\n",
    "            \n",
    "            for line in lines:\n",
    "                if line.startswith('TASK_NUMBER:'):\n",
    "                    try:\n",
    "                        task_number = int(line.replace('TASK_NUMBER:', '').strip()) - 1\n",
    "                    except:\n",
    "                        pass\n",
    "                elif line.startswith('UPDATE_TYPE:'):\n",
    "                    update_type = line.replace('UPDATE_TYPE:', '').strip()\n",
    "                elif line.startswith('UPDATE:'):\n",
    "                    update_description = line.replace('UPDATE:', '').strip()\n",
    "            \n",
    "            if task_number is not None and 0 <= task_number < len(active_tasks):\n",
    "                related_task_id = active_tasks[task_number]['task_id']\n",
    "                \n",
    "                # Generate unique update ID\n",
    "                update_id = str(uuid.uuid4())[:8]\n",
    "                \n",
    "                # Add to task updates dataframe\n",
    "                update_row = {\n",
    "                    'update_id': update_id,\n",
    "                    'task_id': related_task_id,\n",
    "                    'message_id': message_id,\n",
    "                    'from_number': from_number,\n",
    "                    'text_body': message_text,\n",
    "                    'update_type': update_type,\n",
    "                    'update_description': update_description,\n",
    "                    'created_at': created_at\n",
    "                }\n",
    "                \n",
    "                task_updates_df = pd.concat([task_updates_df, pd.DataFrame([update_row])], ignore_index=True)\n",
    "                \n",
    "                print(f\"ðŸ“ Task update found for: {active_tasks[task_number]['title']}\")\n",
    "                \n",
    "                # Update task status if completed\n",
    "                if 'completion' in update_type.lower() or 'complete' in update_description.lower():\n",
    "                    task_requests_df.loc[task_requests_df['task_id'] == related_task_id, 'status'] = 'completed'\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nðŸŽ¯ Found {len(task_requests_df)} task requests\")\n",
    "print(f\"ðŸ“ Found {len(task_updates_df)} task updates\")\n",
    "\n",
    "# Show summary\n",
    "if not task_requests_df.empty:\n",
    "    print(\"\\n=== TASK REQUESTS SUMMARY ===\")\n",
    "    for _, task in task_requests_df.iterrows():\n",
    "        print(f\"Task ID: {task['task_id']}\")\n",
    "        print(f\"Title: {task['task_title']}\")  \n",
    "        print(f\"Requester: {task['from_number']}\")\n",
    "        print(f\"Status: {task['status']}\")\n",
    "        print(f\"Created: {task['created_at']}\")\n",
    "        \n",
    "        # Show related updates\n",
    "        related_updates = task_updates_df[task_updates_df['task_id'] == task['task_id']]\n",
    "        if not related_updates.empty:\n",
    "            print(f\"Updates: {len(related_updates)}\")\n",
    "            for _, update in related_updates.iterrows():\n",
    "                print(f\"  - {update['update_type']}: {update['update_description'][:50]}...\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Save to CSV files\n",
    "task_requests_df.to_csv('task_requests.csv', index=False)\n",
    "task_updates_df.to_csv('task_updates.csv', index=False)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Results saved to 'task_requests.csv' and 'task_updates.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_updates_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "facts = pd.read_csv('user_facts_export.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398960dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6db755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_facts = facts.groupby('from_number')['fact'].apply(list).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab212913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_user_facts(facts_list):\n",
    "    prompt = f\"Here are some facts about a user: {facts_list}. Summarize all the key information in a concise paragraph.\"\n",
    "    summary = llm.invoke(prompt).content\n",
    "    return summary\n",
    "\n",
    "grouped_facts['user_summary'] = grouped_facts['fact'].apply(summarize_user_facts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_facts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_facts['user_summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa54c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
